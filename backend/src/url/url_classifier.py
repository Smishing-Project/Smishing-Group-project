"""
URL ë¶„ë¥˜ê¸° ëª¨ë“ˆ
í•™ìŠµëœ Random Forest ëª¨ë¸ë¡œ URL ìœ„í—˜ë„ ì˜ˆì¸¡
"""

import joblib
import os
from typing import Dict
import numpy as np

from src.url.feature_extractor import URLFeatureExtractor


class URLClassifier:
    """í•™ìŠµëœ ML ëª¨ë¸ë¡œ URL ë¶„ë¥˜"""
    
    def __init__(self, model_dir: str = '/app/models'):
        """
        URL ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        
        Args:
            model_dir: ëª¨ë¸ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
        """
        self.model_dir = model_dir
        self.model = None
        self.feature_names = None
        self.metadata = None
        self.feature_extractor = URLFeatureExtractor()
        
        # ëª¨ë¸ ë¡œë“œ ì‹œë„
        self._load_model()
    
    def _load_model(self):
        """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
        model_path = os.path.join(self.model_dir, 'url_classifier.pkl')
        feature_path = os.path.join(self.model_dir, 'feature_names.pkl')
        metadata_path = os.path.join(self.model_dir, 'metadata.pkl')
        
        if os.path.exists(model_path):
            try:
                self.model = joblib.load(model_path)
                self.feature_names = joblib.load(feature_path)
                self.metadata = joblib.load(metadata_path)
                
                print(f"âœ… URL Classifier ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                print(f"   - ëª¨ë¸: {self.metadata.get('model_type', 'Unknown')}")
                print(f"   - Accuracy: {self.metadata.get('accuracy', 0):.2%}")
                print(f"   - Recall: {self.metadata.get('recall', 0):.2%}")
            except Exception as e:
                print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.model = None
        else:
            print(f"â„¹ï¸ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            print(f"   Google Colabì—ì„œ ëª¨ë¸ì„ í•™ìŠµ í›„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            self.model = None
    
    def is_model_loaded(self) -> bool:
        """ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return self.model is not None
    
    def predict(self, url: str) -> Dict[str, any]:
        """
        URLì˜ ì•…ì„± ì—¬ë¶€ ì˜ˆì¸¡
        
        Args:
            url: ì˜ˆì¸¡í•  URL
        
        Returns:
            dict: {
                'is_malicious': bool,
                'confidence': float,
                'probability': dict,
                'features': dict
            }
        """
        if not self.is_model_loaded():
            return {
                'is_malicious': False,
                'confidence': 0.0,
                'probability': {'benign': 0.5, 'malicious': 0.5},
                'features': {},
                'error': 'Model not loaded'
            }
        
        try:
            # íŠ¹ì§• ì¶”ì¶œ
            features = self.feature_extractor.extract_features(url)
            
            # íŠ¹ì§•ì„ DataFrameìœ¼ë¡œ ë³€í™˜ (ëª¨ë¸ í•™ìŠµ ì‹œ ìˆœì„œì™€ ë™ì¼í•˜ê²Œ)
            import pandas as pd
            features_df = pd.DataFrame([features])[self.feature_names]
            
            # ì˜ˆì¸¡
            prediction = self.model.predict(features_df)[0]
            probabilities = self.model.predict_proba(features_df)[0]
            
            return {
                'is_malicious': bool(prediction == 1),
                'confidence': float(probabilities[prediction]),
                'probability': {
                    'benign': float(probabilities[0]),
                    'malicious': float(probabilities[1])
                },
                'features': features
            }
            
        except Exception as e:
            return {
                'is_malicious': False,
                'confidence': 0.0,
                'probability': {'benign': 0.5, 'malicious': 0.5},
                'features': {},
                'error': f'Prediction failed: {str(e)}'
            }
    
    def predict_batch(self, urls: list) -> list:
        """
        ì—¬ëŸ¬ URL ì¼ê´„ ì˜ˆì¸¡
        
        Args:
            urls: URL ë¦¬ìŠ¤íŠ¸
        
        Returns:
            list: ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        return [self.predict(url) for url in urls]


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    classifier = URLClassifier()
    
    if classifier.is_model_loaded():
        # í…ŒìŠ¤íŠ¸ URL
        test_urls = [
            "https://www.google.com",
            "http://paypal-secure-login.com/verify",
            "http://192.168.1.1/admin"
        ]
        
        for url in test_urls:
            print(f"\nğŸ” URL: {url}")
            result = classifier.predict(url)
            
            if 'error' not in result:
                status = "ì•…ì„±" if result['is_malicious'] else "ì •ìƒ"
                print(f"   ì˜ˆì¸¡: {status} (ì‹ ë¢°ë„: {result['confidence']:.1%})")
                print(f"   í™•ë¥ : ì •ìƒ {result['probability']['benign']:.2%} | "
                      f"ì•…ì„± {result['probability']['malicious']:.2%}")
            else:
                print(f"   ì˜¤ë¥˜: {result['error']}")
    else:
        print("\nâš ï¸ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   Google Colabì—ì„œ ëª¨ë¸ í•™ìŠµ í›„ ë‹¤ìŒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:")
        print("   1. models/url_classifier.pkl")
        print("   2. models/feature_names.pkl")
        print("   3. models/metadata.pkl")
