"""
URL íŠ¹ì§• ì¶”ì¶œ ëª¨ë“ˆ
í”¼ì‹± URL íƒì§€ë¥¼ ìœ„í•œ 30ê°œ íŠ¹ì§• ì¶”ì¶œ
"""

import re
import socket
from urllib.parse import urlparse
from typing import Dict, List
import tldextract
import whois
from datetime import datetime


class URLFeatureExtractor:
    """URLì—ì„œ ML ëª¨ë¸ìš© íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        """íŠ¹ì§• ì¶”ì¶œê¸° ì´ˆê¸°í™”"""
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        self.suspicious_keywords = [
            'login', 'signin', 'account', 'update', 'secure', 'banking',
            'verify', 'confirm', 'password', 'credit', 'paypal', 'amazon',
            'ebay', 'apple', 'google', 'microsoft', 'facebook', 'netflix',
            'suspended', 'locked', 'unusual', 'alert', 'urgent'
        ]
        
        # TLD (Top-Level Domain) ì‹ ë¢°ë„
        self.trusted_tlds = ['com', 'org', 'net', 'edu', 'gov', 'mil']
        
        print("âœ… URL Feature Extractor ì´ˆê¸°í™” ì™„ë£Œ")
    
    def extract_features(self, url: str) -> Dict[str, float]:
        """
        URLì—ì„œ 30ê°œ íŠ¹ì§• ì¶”ì¶œ
        
        Args:
            url: ë¶„ì„í•  URL
        
        Returns:
            dict: íŠ¹ì§• ì´ë¦„ê³¼ ê°’ì˜ ë”•ì…”ë„ˆë¦¬
        """
        features = {}
        
        try:
            # URL íŒŒì‹±
            parsed = urlparse(url)
            extracted = tldextract.extract(url)
            
            # 1-10: URL êµ¬ì¡° íŠ¹ì§•
            features.update(self._extract_url_structure_features(url, parsed, extracted))
            
            # 11-20: ë„ë©”ì¸ íŠ¹ì§•
            features.update(self._extract_domain_features(parsed, extracted))
            
            # 21-30: ì½˜í…ì¸  íŠ¹ì§•
            features.update(self._extract_content_features(url, parsed))
            
        except Exception as e:
            print(f"âš ï¸ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            features = self._get_default_features()
        
        return features
    
    def _extract_url_structure_features(
        self, 
        url: str, 
        parsed, 
        extracted
    ) -> Dict[str, float]:
        """URL êµ¬ì¡° ê´€ë ¨ íŠ¹ì§• (1-10)"""
        features = {}
        
        # 1. URL ê¸¸ì´
        features['url_length'] = len(url)
        
        # 2. ë„ë©”ì¸ ê¸¸ì´
        features['domain_length'] = len(parsed.netloc)
        
        # 3. ê²½ë¡œ ê¸¸ì´
        features['path_length'] = len(parsed.path)
        
        # 4. í•˜ì´í”ˆ ê°œìˆ˜
        features['hyphen_count'] = url.count('-')
        
        # 5. ì–¸ë”ìŠ¤ì½”ì–´ ê°œìˆ˜
        features['underscore_count'] = url.count('_')
        
        # 6. ìŠ¬ë˜ì‹œ ê°œìˆ˜
        features['slash_count'] = url.count('/')
        
        # 7. ì (.) ê°œìˆ˜
        features['dot_count'] = url.count('.')
        
        # 8. @ ê¸°í˜¸ ì¡´ì¬ ì—¬ë¶€ (í”¼ì‹±ì— ìì£¼ ì‚¬ìš©)
        features['has_at_symbol'] = 1 if '@' in url else 0
        
        # 9. ìˆ«ì ê°œìˆ˜
        features['digit_count'] = sum(c.isdigit() for c in url)
        
        # 10. íŠ¹ìˆ˜ë¬¸ì ê°œìˆ˜
        special_chars = re.findall(r'[!#$%&*+=?^`{|}~]', url)
        features['special_char_count'] = len(special_chars)
        
        return features
    
    def _extract_domain_features(self, parsed, extracted) -> Dict[str, float]:
        """ë„ë©”ì¸ ê´€ë ¨ íŠ¹ì§• (11-20)"""
        features = {}
        
        domain = parsed.netloc
        
        # 11. IP ì£¼ì†Œ ì‚¬ìš© ì—¬ë¶€
        features['is_ip_address'] = 1 if self._is_ip_address(domain) else 0
        
        # 12. ì„œë¸Œë„ë©”ì¸ ê°œìˆ˜
        subdomain = extracted.subdomain
        features['subdomain_count'] = len(subdomain.split('.')) if subdomain else 0
        
        # 13. ë„ë©”ì¸ì— ìˆ«ì í¬í•¨ ì—¬ë¶€
        features['domain_has_digits'] = 1 if any(c.isdigit() for c in domain) else 0
        
        # 14. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” TLD ì—¬ë¶€
        tld = extracted.suffix
        features['is_trusted_tld'] = 1 if tld in self.trusted_tlds else 0
        
        # 15. www ì ‘ë‘ì‚¬ ì¡´ì¬ ì—¬ë¶€
        features['has_www'] = 1 if domain.startswith('www.') else 0
        
        # 16. ë„ë©”ì¸ì— í•˜ì´í”ˆ ê°œìˆ˜
        features['domain_hyphen_count'] = domain.count('-')
        
        # 17. ë„ë©”ì¸ ì—”íŠ¸ë¡œí”¼ (ë³µì¡ë„)
        features['domain_entropy'] = self._calculate_entropy(domain)
        
        # 18. ë„ë©”ì¸ì´ ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ”ì§€
        features['starts_with_digit'] = 1 if domain and domain[0].isdigit() else 0
        
        # 19. ë„ë©”ì¸ ì (.) ê°œìˆ˜
        features['domain_dot_count'] = domain.count('.')
        
        # 20. ê¸´ ë„ë©”ì¸ ì—¬ë¶€ (15ì ì´ìƒ)
        features['is_long_domain'] = 1 if len(domain) > 15 else 0
        
        return features
    
    def _extract_content_features(self, url: str, parsed) -> Dict[str, float]:
        """ì½˜í…ì¸  ê´€ë ¨ íŠ¹ì§• (21-30)"""
        features = {}
        
        url_lower = url.lower()
        
        # 21. HTTPS ì‚¬ìš© ì—¬ë¶€
        features['is_https'] = 1 if parsed.scheme == 'https' else 0
        
        # 22. í¬íŠ¸ ë²ˆí˜¸ ëª…ì‹œ ì—¬ë¶€
        features['has_port'] = 1 if ':' in parsed.netloc and not parsed.netloc.startswith('[') else 0
        
        # 23. ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í‚¤ì›Œë“œ ê°œìˆ˜
        suspicious_count = sum(1 for keyword in self.suspicious_keywords if keyword in url_lower)
        features['suspicious_keyword_count'] = suspicious_count
        
        # 24. ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ê°œìˆ˜
        query_params = parsed.query.split('&') if parsed.query else []
        features['query_param_count'] = len(query_params)
        
        # 25. Fragment ì¡´ì¬ ì—¬ë¶€
        features['has_fragment'] = 1 if parsed.fragment else 0
        
        # 26. ê²½ë¡œ ê¹Šì´ (ìŠ¬ë˜ì‹œ ê°œìˆ˜)
        path_depth = len([p for p in parsed.path.split('/') if p])
        features['path_depth'] = path_depth
        
        # 27. íŒŒì¼ í™•ì¥ì ì¡´ì¬ ì—¬ë¶€
        path = parsed.path
        features['has_file_extension'] = 1 if '.' in path.split('/')[-1] else 0
        
        # 28. URLì— ì¤‘ë³µ ë¬¸ì íŒ¨í„´ (aaa, 111 ë“±)
        features['has_repetitive_chars'] = 1 if re.search(r'(.)\1{2,}', url) else 0
        
        # 29. ë„ë©”ì¸ê³¼ ë¸Œëœë“œëª… ë¶ˆì¼ì¹˜ (ì˜ˆ: paypal-secure.com)
        features['brand_mismatch'] = self._check_brand_mismatch(url_lower)
        
        # 30. ë‹¨ì¶• URL ì—¬ë¶€
        short_url_domains = ['bit.ly', 't.co', 'goo.gl', 'tinyurl.com', 'ow.ly']
        features['is_shortened_url'] = 1 if any(domain in url_lower for domain in short_url_domains) else 0
        
        return features
    
    def _is_ip_address(self, domain: str) -> bool:
        """ë„ë©”ì¸ì´ IP ì£¼ì†Œì¸ì§€ í™•ì¸"""
        # IPv4 íŒ¨í„´
        ipv4_pattern = r'^(\d{1,3}\.){3}\d{1,3}$'
        if re.match(ipv4_pattern, domain):
            return True
        
        # IPv6 íŒ¨í„´ (ê°„ë‹¨í•œ ì²´í¬)
        if ':' in domain and not domain.startswith('['):
            return True
        
        return False
    
    def _calculate_entropy(self, text: str) -> float:
        """ë¬¸ìì—´ì˜ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ë³µì¡ë„ ì¸¡ì •)"""
        if not text:
            return 0.0
        
        from collections import Counter
        import math
        
        # ë¬¸ì ë¹ˆë„ ê³„ì‚°
        char_freq = Counter(text)
        text_len = len(text)
        
        # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
        entropy = 0.0
        for count in char_freq.values():
            probability = count / text_len
            entropy -= probability * math.log2(probability)
        
        return round(entropy, 4)
    
    def _check_brand_mismatch(self, url: str) -> int:
        """ë¸Œëœë“œëª… ë¶ˆì¼ì¹˜ ê²€ì‚¬"""
        # ìœ ëª… ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸
        brands = ['paypal', 'amazon', 'google', 'apple', 'microsoft', 
                  'facebook', 'netflix', 'ebay', 'bank', 'secure']
        
        # URLì— ë¸Œëœë“œëª…ì´ ìˆì§€ë§Œ ì‹¤ì œ ë„ë©”ì¸ì´ ì•„ë‹Œ ê²½ìš°
        for brand in brands:
            if brand in url:
                # ë„ë©”ì¸ì´ ì‹¤ì œë¡œ í•´ë‹¹ ë¸Œëœë“œê°€ ì•„ë‹ˆë©´ ì˜ì‹¬
                if f'{brand}.com' not in url and f'{brand}.net' not in url:
                    return 1
        
        return 0
    
    def _get_default_features(self) -> Dict[str, float]:
        """ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ íŠ¹ì§• ê°’ ë°˜í™˜"""
        feature_names = [
            'url_length', 'domain_length', 'path_length', 'hyphen_count',
            'underscore_count', 'slash_count', 'dot_count', 'has_at_symbol',
            'digit_count', 'special_char_count', 'is_ip_address', 'subdomain_count',
            'domain_has_digits', 'is_trusted_tld', 'has_www', 'domain_hyphen_count',
            'domain_entropy', 'starts_with_digit', 'domain_dot_count', 'is_long_domain',
            'is_https', 'has_port', 'suspicious_keyword_count', 'query_param_count',
            'has_fragment', 'path_depth', 'has_file_extension', 'has_repetitive_chars',
            'brand_mismatch', 'is_shortened_url'
        ]
        
        return {name: 0.0 for name in feature_names}
    
    def get_feature_names(self) -> List[str]:
        """íŠ¹ì§• ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (í•™ìŠµ ì‹œ ì‚¬ìš©)"""
        return [
            'url_length', 'domain_length', 'path_length', 'hyphen_count',
            'underscore_count', 'slash_count', 'dot_count', 'has_at_symbol',
            'digit_count', 'special_char_count', 'is_ip_address', 'subdomain_count',
            'domain_has_digits', 'is_trusted_tld', 'has_www', 'domain_hyphen_count',
            'domain_entropy', 'starts_with_digit', 'domain_dot_count', 'is_long_domain',
            'is_https', 'has_port', 'suspicious_keyword_count', 'query_param_count',
            'has_fragment', 'path_depth', 'has_file_extension', 'has_repetitive_chars',
            'brand_mismatch', 'is_shortened_url'
        ]


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    extractor = URLFeatureExtractor()
    
    # í…ŒìŠ¤íŠ¸ URL
    test_urls = [
        "https://www.google.com",
        "http://paypal-secure-login.com/verify",
        "http://192.168.1.1/admin",
        "http://bit.ly/abc123"
    ]
    
    for url in test_urls:
        print(f"\nğŸ” URL: {url}")
        features = extractor.extract_features(url)
        print(f"íŠ¹ì§• ê°œìˆ˜: {len(features)}")
        print(f"ì£¼ìš” íŠ¹ì§•:")
        for key, value in list(features.items())[:5]:
            print(f"  - {key}: {value}")
